input {
    file {
        type => "icgc-donor"
        # This is necessary to ensure that the file is
        # processed in full. Without it logstash will default
        # to only processing new entries to the file (as would
        # be seen with a logfile for a live application, but
        # not static data like we're working with here)
        start_position  => "beginning"
        # This is the full path to the file to process.
        # Wildcards are valid.
        path =>  "/data/donor.tsv"
        # If I'm testing with a small test log that I want to repeatedly restart I just turn off the sincedb:
        # This config causes logstash to start at the beginning of the file every time.
        sincedb_path => "/dev/null"
    }
}


filter {
  if [type] == "icgc-donor" {
        # Process the input using the csv filter.
        # The list of column names I took manually from the
        # file itself
        csv {
                # note: this must be an actual tab character
                separator => "	"
                columns => ["icgc_donor_id",
                  "project_code",
                  "study_donor_involved_in",
                  "submitted_donor_id",
                  "donor_sex",
                  "donor_vital_status",
                  "disease_status_last_followup",
                  "donor_relapse_type",
                  "donor_age_at_diagnosis",
                  "donor_age_at_enrollment",
                  "donor_age_at_last_followup",
                  "donor_relapse_interval",
                  "donor_diagnosis_icd10",
                  "donor_tumour_staging_system_at_diagnosis",
                  "donor_tumour_stage_at_diagnosis",
                  "donor_tumour_stage_at_diagnosis_supplemental",
                  "donor_survival_time",
                  "donor_interval_of_last_followup",
                  "prior_malignancy",
                  "cancer_type_prior_malignancy",
                  "cancer_history_first_degree_relative"]

                  add_field => {
                    "description" => "A %{donor_vital_status} %{donor_age_at_diagnosis} %{donor_sex} with %{donor_diagnosis_icd10} %{disease_status_last_followup}"
                    "species" => "NCBITaxon:9606"
                  }

            }

        if [icgc_donor_id] == "icgc_donor_id" {
          drop {}
        }


        if [donor_sex] {
          mutate { add_field => { "sex" => "%{donor_sex}" } }
        } else {
          mutate { add_field => { "sex" => "UNKNOWN" } }
        }


        mutate {
          # Renames the 'XXX' field to 'YYY'
          # rename => { "XXX" => "YYY" }
          #
          uppercase => [ "sex" ]
          convert => {"donation_total" => "integer" }
          convert => {"donor_age_at_diagnosis" => "integer" }
          convert => {"donor_age_at_enrollment" => "integer" }
          convert => {"donor_age_at_last_followup" => "integer" }
          convert => {"donor_relapse_interval donor_survival_time" => "integer" }
          convert => {"donor_interval_of_last_followup" => "integer" }
        }
  }
}

output {
  if [type] == "icgc-donor" {
        # Now send it to Elasticsearch which here is running
        # on the same machine.
        elasticsearch {
          hosts => ["192.168.99.100:9201"]
          index => "individual-icgc"
          document_type => "individual"
          document_id => "%{project_code}-%{icgc_donor_id}"
          # see https://www.elastic.co/blog/new-in-logstash-1-3-elasticsearch-index-template-management
          template_overwrite => true
       	  template => "/data/default_index_template.json"
        }
        stdout { codec => rubydebug }
  }
}
