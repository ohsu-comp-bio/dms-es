input {
    file {
        type => "tcga-resource"
        # This is necessary to ensure that the file is
        # processed in full. Without it logstash will default
        # to only processing new entries to the file (as would
        # be seen with a logfile for a live application, but
        # not static data like we're working with here)
        start_position  => "beginning"
        # This is the full path to the file to process.
        # Wildcards are valid.
        path =>  "/data/PRAD_bio.resource.txt"
        # If I'm testing with a small test log that I want to repeatedly restart I just turn off the sincedb:
        # This config causes logstash to start at the beginning of the file every time.
        sincedb_path => "/dev/null"
    }
}


filter {
  if [type] == "tcga-resource" {
        # Process the input using the csv filter.
        # The list of column names I took manually from the
        # file itself
        csv {

                # note: this must be an actual tab character
                separator => "	"
                columns => ["aliquot_id",
                            "file_id",
                            "protocol_ref",
                            "protocol_component_versions",
                            "parent_alignment_ref",
                            "gene_annotation_ref",
                            "data_transformation_name",
                            "derived_data_file",
                            "tcga_data_type",
                            "tcga_data_level",
                            "tcga_archive_name"
                           ]

                  # see http://docs.ckan.org/en/ckan-1.7.2/domain-model-resource.html
                  # for inspiration
                  add_field => {
                     "individual_id" => "%{project_code}-%{patient_id}"
                     "sample_id" => "%{project_code}-%{sample_id}"
                     "portion_id" => "%{project_code}-%{portion_id}"
                     "analyte_id" => "%{project_code}-%{analyte_id}"
                     "aliquot_id" => "%{project_code}-%{aliquot_id}"
                     "ccc_did" => "%{project_code}-%{aliquot_id}:uuid"
                     "url" => "/%{project_code}/%{patient_id}/%{sample_id}/%{portion_id}/%{analyte_id}/%{aliquot_id}/uuid"
                     "format" => "%{tcga_data_type}"
                     "resource_type" => "file"
                     "mimetype" => "text/tab-separated-values"
                     "description" => "A %{resource_type}"         
                   }

            }

        if [tcga_donor_id] == "tcga_donor_id" {
          drop {}
        }
        if [tcga_data_type] == "tcga_data_type" {
          drop {}
        }
        uuid {
          target    => "ccc_did"
          overwrite => true
        }

  }
}

output {
  if [type] == "tcga-resource" {
        # Now send it to Elasticsearch which here is running
        # on the same machine.
        elasticsearch {
          hosts => ["elasticsearch:9200"]
          index => "resource-tcga"
          document_type => "resource"
          document_id => "%{ccc_did}"
          # see https://www.elastic.co/blog/new-in-logstash-1-3-elasticsearch-index-template-management
          template_overwrite => true
       	  template => "/data/default_index_template.json"
        }
        stdout { codec => rubydebug }
  }
}
